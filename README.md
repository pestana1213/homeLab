# ğŸ  Meu Homelab com Ubuntu Server

Este repositÃ³rio documenta a criaÃ§Ã£o e manutenÃ§Ã£o do meu homelab, hospedado num portÃ¡til com Ubuntu Server.
Objetivo: Aprender Docker, automaÃ§Ã£o, auto-hospedagem e manter serviÃ§os pessoais como Nextcloud, Pi-hole, dashboards e inteligÃªncia artificial local.

## ğŸ§± Infraestrutura

* ğŸ’» Host: Intel i7, 16GB RAM, 512GB SSD + 1TB HDD
* ğŸ§ SO: Ubuntu Server 24.04 LTS
* ğŸ³ Docker + Docker Compose
* ğŸ“¡ Acesso via SSH e web

## ğŸ“¦ ServiÃ§os

| ServiÃ§o   | DescriÃ§Ã£o                                           |
| --------- | --------------------------------------------------- |
| Pi-hole   | Bloqueador de anÃºncios na rede                      |
| Nextcloud | Nuvem pessoal                                       |
| Dashy     | Painel com atalhos dos serviÃ§os                     |
| myAi      | Ollama (modelos de IA) + Open WebUI (ChatGPT local) |

## ğŸ¤– Modelos de IA suportados (CPU only)

Os modelos sÃ£o geridos pelo **Ollama** e podem ser trocados facilmente no Open WebUI.

### **Modelos recomendados**

* **Mistral 7B** â†’ rÃ¡pido, eficiente e boa qualidade geral
* **LLaMA 2 7B Chat** â†’ respostas estilo ChatGPT
* **CodeLlama 7B** â†’ focado em programaÃ§Ã£o

### **Comandos para baixar os modelos**

```bash
docker exec -it ollama ollama pull mistral
docker exec -it ollama ollama pull llama2
docker exec -it ollama ollama pull codellama
```

### **Como usar no Open WebUI**

1. Aceder: `http://{host}:3000`
2. Ir em **Settings â†’ Model**
3. Selecionar o modelo desejado (mistral, llama2, codellama)

> **Notas:**  Modelos 7B usam \~5â€“7GB de RAM, ideais para CPU. Modelos 13B funcionam mas sÃ£o bem mais lentos em CPU.

## ğŸš€ Iniciar todos os containers

```bash
chmod +x initialize.sh
./initialize.sh
```

## ğŸ›‘ Parar todos os containers

```bash
chmod +x stop.sh
./stop.sh
```

## ğŸŒ URL do Dashy

Acede ao painel Dashy no navegador atravÃ©s do endereÃ§o:

```bash
http://{host}:8080
```

Substitui {host} pelo IP ou nome do teu servidor.
